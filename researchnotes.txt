# https://www.youtube.com/watch?v=4HKqjENq9OU
"Because KNN is based on feature similarity, we can do classification using KNN classifier."
KNN is a Supervised Machine Learning Algorithm that classifies a data point according to its similarity to its neighbors.
parameter tuning is used to improve accuracy. where k is drastically changes the answer.
choosing to high or low a "k-value" distorts the value.
sqrt k
if even make an odd k number by adding one or subtracting one from the root
be specific with the data needed
knn may struggle to extract the correct patterns
nearest neighbors can be found using the Euclidean distance formula:
d = √[(x2 – x1)^2 + (y2 – y1)^2]

Test for Euclidean distance --(1)



14-15m example




# https://www.youtube.com/watch?v=ojjnd5gEMuk

find minimum spanning tree using the graph of data per column
then cross out the rows
find nearest bound using nearest neighbor method to know what optimal solution
may be

Find MST (0)

# https://youtu.be/rTEtEy5o3X0
fit functions train the datasets

predict function does the calculations
_predict function is a helper that obtains one data point

euclidean distance global function is used
with help of numpy

#https://www.youtube.com/watch?v=YYEJ_GUguHw
https://github.com/AssemblyAI-Examples/Machine-Learning-From-Scratch
was able to get a .92 accuracy rate

Test for most accurate path(3)


# https://www.youtube.com/watch?v=xtaom__-drE
# https://www.neuralnine.com/k-nearest-neighbors-classification-from-scratch-in-python/
euclidean formula can go in multiple dimensions to find the nearest neighbor
subtract one numpy array from another numpy array, is every val in p minus every val in q is the result
square the result, sum it, then sqrt it, finally return it

fit function is used for training the points
Color points(2)

# https://www.youtube.com/watch?v=KURydVL0kGQ
See if self-adjusting algorithm aligns(4)


at end, compare djikstra and genetic algorithms, stating in the future you would use genetic